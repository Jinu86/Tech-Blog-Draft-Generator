import streamlit as st
import google.generativeai as genai
import os
import time

# Gemini API ì„¤ì •
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
model = genai.GenerativeModel("gemini-1.5-pro")

# ì´ˆê¸° ì„¸ì…˜ ìƒíƒœ ì„¤ì •
def init_session():
    if "step" not in st.session_state:
        st.session_state.update({
            "step": 1,
            "topic": "",
            "keywords": [],
            "audience": "",
            "style": "",
            "structure": "",
            "headings": [],
            "draft": "",
            "history": [],
            "chat_input": "",
            "chat_log": []
        })

# Gemini API í˜¸ì¶œ í•¨ìˆ˜
def ask_gemini(prompt):
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# ReAct ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
def react_prompt(context, question):
    return f"""
ë‹¹ì‹ ì€ ê¸°ìˆ  ë¸”ë¡œê·¸ ìž‘ì„±ì„ ë„ì™€ì£¼ëŠ” ì±—ë´‡ìž…ë‹ˆë‹¤.
ReAct ë°©ì‹(ì§ˆë¬¸â†’ë‹µë³€â†’ì¶”ë¡ â†’ë‹¤ìŒ ì§ˆë¬¸)ìœ¼ë¡œ ì‚¬ìš©ìžì˜ ì •ë³´ë¥¼ ë‹¨ê³„ë³„ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

ê·œì¹™:
- ë°˜ë“œì‹œ ì±—ë´‡ì´ ë¨¼ì € ì§ˆë¬¸í•©ë‹ˆë‹¤.
- ì‚¬ìš©ìžì˜ ì‘ë‹µì´ ë¶ˆì¶©ë¶„í•˜ë©´ ë³´ì¶© ì§ˆë¬¸ì„ í•˜ì„¸ìš”.
- ì‚¬ìš©ìžì˜ ì‘ë‹µì„ ìš”ì•½í•˜ê³ , ìš”ì•½í•œ ë‚´ìš©ì´ ë§žëŠ”ì§€ í™•ì¸ ì§ˆë¬¸ì„ í•˜ì„¸ìš”.
- ì‚¬ìš©ìžê°€ í™•ì¸í•´ì•¼ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.
- ëŒ€í™”ëŠ” ì¼ë°˜ì ì¸ ì±„íŒ… í˜•íƒœë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.

í˜„ìž¬ ë¬¸ë§¥:
{context}

ì±—ë´‡ì´ ì‚¬ìš©ìžì—ê²Œ ë˜ì§ˆ ì§ˆë¬¸:
{question}

ì´ì œ ì‚¬ìš©ìžì—ê²Œ ìžì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.
"""

# ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ì„¤ê³„
def step_prompt():
    step = st.session_state.step
    if step == 1:
        return react_prompt("", "ê¸°ìˆ  ë¸”ë¡œê·¸ë¥¼ ìž‘ì„±í•  ì£¼ì œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. ê°€ëŠ¥í•œ êµ¬ì²´ì ì¼ìˆ˜ë¡ ì¢‹ì•„ìš”.")
    elif step == 2:
        return react_prompt(f"ì£¼ì œ: {st.session_state.topic}", "ê·¸ ì£¼ì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸€ì˜ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì œì•ˆë“œë¦´ê²Œìš”. ì´ ì¤‘ì—ì„œ ì„ íƒí•˜ê±°ë‚˜ ì§ì ‘ ì¶”ê°€í•´ì£¼ì…”ë„ ë¼ìš”.")
    elif step == 3:
        return react_prompt(f"ì£¼ì œ: {st.session_state.topic}, í‚¤ì›Œë“œ: {', '.join(st.session_state.keywords)}", "ì´ ê¸€ì€ ì–´ë–¤ ë¶„ë“¤ì´ ì½ì„ê¹Œìš”? ì˜ˆ: ìž…ë¬¸ìž, ì‹¤ë¬´ìž, ë°œí‘œ ì²­ì¤‘ ë“±")
    elif step == 4:
        return react_prompt("", "ê¸€ì˜ ì „ì²´ì ì¸ êµ¬ì„±ì€ ì–´ë–»ê²Œ í• ê¹Œìš”? ì˜ˆ: ì„œë¡ â€“ë³¸ë¬¸â€“ê²°ë¡ , ë¬¸ì œâ€“í•´ê²°, ì½”ë“œâ€“ì„¤ëª… ë°˜ë³µ ë“±")
    elif step == 5:
        return react_prompt(f"ì£¼ì œ: {st.session_state.topic}, í‚¤ì›Œë“œ: {', '.join(st.session_state.keywords)}, êµ¬ì¡°: {st.session_state.structure}", "ì „ì²´ ê¸€ì„ êµ¬ì„±í•  ì†Œì œëª©ì„ ì œì•ˆë“œë¦´ê²Œìš”. ìˆ˜ì •í•˜ê±°ë‚˜ ìƒˆë¡œ ìž…ë ¥í•˜ì…”ë„ ë©ë‹ˆë‹¤.")
    elif step == 6:
        return react_prompt(f"ì£¼ì œ: {st.session_state.topic}\ní‚¤ì›Œë“œ: {', '.join(st.session_state.keywords)}\nì˜ˆìƒ ë…ìž: {st.session_state.audience}\nêµ¬ì¡°: {st.session_state.structure}\nì†Œì œëª©: {', '.join(st.session_state.headings)}", "ì´ì œ ì „ì²´ ì´ˆì•ˆì„ ìž‘ì„±í• ê²Œìš”. ìŠ¤íƒ€ì¼, êµ¬ì¡°, í‚¤ì›Œë“œ, ì†Œì œëª©ì„ ë°˜ì˜í•´ì„œ ìž‘ì„±í•˜ê² ìŠµë‹ˆë‹¤.")
    return ""

# ì‚¬ìš©ìžì˜ ì‘ë‹µì„ ë¶„ì„í•´ì„œ ìƒíƒœ ì €ìž¥ (ê°„ë‹¨í•œ ì¶”ì¶œ)
def parse_user_reply(reply):
    step = st.session_state.step
    if step == 1:
        st.session_state.topic = reply
    elif step == 2:
        st.session_state.keywords = [kw.strip() for kw in reply.split() if len(kw) > 1]
    elif step == 3:
        st.session_state.audience = reply
    elif step == 4:
        st.session_state.structure = reply
    elif step == 5:
        st.session_state.headings = [h.strip("- ") for h in reply.split("\n") if h.strip()]
    elif step == 6:
        st.session_state.draft = reply

    st.session_state.history.append((f"step{step}", reply))
    st.session_state.step += 1

# Streamlit ì•± ì‹¤í–‰ í•¨ìˆ˜
def run_app():
    st.set_page_config(page_title="ê¸°ìˆ  ë¸”ë¡œê·¸ ìž‘ì„± ë„ìš°ë¯¸", layout="wide")
    st.title("ðŸ“ ê¸°ìˆ  ë¸”ë¡œê·¸ ì´ˆì•ˆ ìž‘ì„± ì±—ë´‡")
    init_session()

    # ì±„íŒ… ì¸í„°íŽ˜ì´ìŠ¤
    chat_log = st.container()
    with chat_log:
        for speaker, message in st.session_state.chat_log:
            if speaker == "user":
                st.chat_message("user").markdown(message)
            else:
                st.chat_message("assistant").markdown(message)

    # ì‚¬ìš©ìž ìž…ë ¥
    user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ìž…ë ¥í•˜ì„¸ìš”")
    if user_input:
        st.session_state.chat_log.append(("user", user_input))
        parse_user_reply(user_input)

        # ë‹¤ìŒ ë‹¨ê³„ ì§ˆë¬¸ ìƒì„±
        prompt = step_prompt()
        response = ask_gemini(prompt)
        st.session_state.chat_log.append(("assistant", response))
        st.rerun()

    # ë§ˆì§€ë§‰ ë‹¨ê³„ì—ì„œ ì´ˆì•ˆ ì¶œë ¥
    if st.session_state.step > 6 and st.session_state.draft:
        st.markdown("#### âœ¨ ìµœì¢… ë¸”ë¡œê·¸ ì´ˆì•ˆ (Markdown) âœ¨")
        st.code(st.session_state.draft, language="markdown")

if __name__ == "__main__":
    run_app()

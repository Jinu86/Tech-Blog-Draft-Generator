import streamlit as st
import google.generativeai as genai
import time
import os
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# Gemini API ì„¤ì •
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
model = genai.GenerativeModel("gemini-1.5-pro")

# ì´ˆê¸° ì„¸ì…˜ ìƒíƒœ ì„¤ì •
def init_session():
    st.session_state.setdefault("step", 1)
    st.session_state.setdefault("topic", "")
    st.session_state.setdefault("keywords", [])
    st.session_state.setdefault("audience", "")
    st.session_state.setdefault("style", "")
    st.session_state.setdefault("structure", "")
    st.session_state.setdefault("headings", [])
    st.session_state.setdefault("draft", "")
    st.session_state.setdefault("messages", [])
    st.session_state.setdefault("waiting_for_input", True)
    
# ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ë©”ì‹œì§€ ì¶”ê°€
def add_message(role, content):
    st.session_state.messages.append({"role": role, "content": content})

# ReAct í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
def react_prompt(context, question):
    return f"""
ë‹¹ì‹ ì€ ê¸°ìˆ  ë¸”ë¡œê·¸ ì‘ì„±ì„ ë„ì™€ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. ëª¨ë“  ëŒ€í™”ëŠ” ReAct ë°©ì‹(ì§ˆë¬¸â†’ì‘ë‹µâ†’ì¶”ë¡ â†’ë‹¤ìŒ ì§ˆë¬¸)ìœ¼ë¡œ ì§„í–‰ë˜ì–´ì•¼ í•˜ë©°,
ëª¨ë“  ë‹¨ê³„ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì›ì¹™ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤:

1. ì±—ë´‡ì´ ë¨¼ì € ì§ˆë¬¸í•©ë‹ˆë‹¤.
2. ì‘ë‹µì´ ë¶ˆì¶©ë¶„í•  ê²½ìš°, ëª…í™•íˆ ì¬ì§ˆë¬¸í•©ë‹ˆë‹¤.
3. ì‘ë‹µì— ëŒ€í•´ ì±—ë´‡ì´ ì´í•´í•œ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ì‚¬ìš©ìì—ê²Œ ì¬í™•ì¸í•©ë‹ˆë‹¤.
4. ìµœì¢… í™•ì¸ì„ ë°›ì€ ë’¤ì—ì•¼ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.
5. ì˜ˆì‹œëŠ” í•„ìš” ì‹œ ì œê³µë©ë‹ˆë‹¤.

í˜„ì¬ê¹Œì§€ ì‚¬ìš©ìì™€ì˜ ëŒ€í™” ë¬¸ë§¥:
{context}

ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ì–»ê³ ì í•˜ëŠ” ì§ˆë¬¸:
{question}

ìœ„ ì›ì¹™ì— ë”°ë¼ ì‚¬ìš©ìì—ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”:
"""

# ë‹¨ê³„ ì§„í–‰ í™•ì¸ í”„ë¡¬í”„íŠ¸
def check_confirmation_prompt(step, user_input, context):
    prompts = {
        1: f"ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì£¼ì œ: '{user_input}'ì— ëŒ€í•´, ì´ê²ƒì´ ê¸°ìˆ  ë¸”ë¡œê·¸ ì£¼ì œë¡œ ì ì ˆí•œì§€ í‰ê°€í•˜ê³ , ì‚¬ìš©ìê°€ 'ë„¤', 'ì¢‹ì•„ìš”', 'ë§ì•„ìš”', 'ë§ìŠµë‹ˆë‹¤', 'ë‹¤ìŒ ë‹¨ê³„ë¡œ', 'ì§„í–‰í•´ì£¼ì„¸ìš”' ë“± í™•ì • ì˜ì‚¬ë¥¼ í‘œí˜„í–ˆëŠ”ì§€ ë¶„ì„í•˜ì„¸ìš”. í™•ì • ì˜ì‚¬ê°€ ìˆìœ¼ë©´ 'CONFIRMED'ë¥¼, ì—†ìœ¼ë©´ 'NEEDS_CONFIRMATION'ì„ ë°˜í™˜í•˜ì„¸ìš”.",
        2: f"ì‚¬ìš©ìê°€ ì…ë ¥í•œ í‚¤ì›Œë“œ: '{user_input}'ì— ëŒ€í•´, ì´ê²ƒì´ ì•ì„œ ë…¼ì˜í•œ ì£¼ì œì™€ ê´€ë ¨ëœ ì ì ˆí•œ í‚¤ì›Œë“œì¸ì§€ í‰ê°€í•˜ê³ , ì‚¬ìš©ìê°€ í™•ì • ì˜ì‚¬('ë„¤', 'ì¢‹ì•„ìš”', 'ì¢‹ìŠµë‹ˆë‹¤', 'ë‹¤ìŒ', 'ì§„í–‰' ë“±)ë¥¼ í‘œí˜„í–ˆëŠ”ì§€ ë¶„ì„í•˜ì„¸ìš”. í™•ì • ì˜ì‚¬ê°€ ìˆìœ¼ë©´ 'CONFIRMED'ë¥¼, ì—†ìœ¼ë©´ 'NEEDS_CONFIRMATION'ì„ ë°˜í™˜í•˜ì„¸ìš”.",
        3: f"ì‚¬ìš©ìê°€ ì…ë ¥í•œ ëŒ€ìƒ ë…ì: '{user_input}'ì— ëŒ€í•´, ì´ê²ƒì´ ëª…í™•í•œ ëŒ€ìƒ ë…ìë¥¼ ë‚˜íƒ€ë‚´ëŠ”ì§€ í‰ê°€í•˜ê³ , ì‚¬ìš©ìê°€ í™•ì • ì˜ì‚¬('ë„¤', 'ì¢‹ì•„ìš”', 'ì¢‹ìŠµë‹ˆë‹¤', 'ë‹¤ìŒ', 'ì§„í–‰' ë“±)ë¥¼ í‘œí˜„í–ˆëŠ”ì§€ ë¶„ì„í•˜ì„¸ìš”. í™•ì • ì˜ì‚¬ê°€ ìˆìœ¼ë©´ 'CONFIRMED'ë¥¼, ì—†ìœ¼ë©´ 'NEEDS_CONFIRMATION'ì„ ë°˜í™˜í•˜ì„¸ìš”.",
        4: f"ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê¸€ êµ¬ì¡°: '{user_input}'ì— ëŒ€í•´, ì´ê²ƒì´ ëª…í™•í•œ ê¸€ êµ¬ì¡°ë¥¼ ë‚˜íƒ€ë‚´ëŠ”ì§€ í‰ê°€í•˜ê³ , ì‚¬ìš©ìê°€ í™•ì • ì˜ì‚¬('ë„¤', 'ì¢‹ì•„ìš”', 'ì¢‹ìŠµë‹ˆë‹¤', 'ë‹¤ìŒ', 'ì§„í–‰' ë“±)ë¥¼ í‘œí˜„í–ˆëŠ”ì§€ ë¶„ì„í•˜ì„¸ìš”. í™•ì • ì˜ì‚¬ê°€ ìˆìœ¼ë©´ 'CONFIRMED'ë¥¼, ì—†ìœ¼ë©´ 'NEEDS_CONFIRMATION'ì„ ë°˜í™˜í•˜ì„¸ìš”.",
        5: f"ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì†Œì œëª©: '{user_input}'ì— ëŒ€í•´, ì´ê²ƒì´ ì•ì„œ ë…¼ì˜í•œ ì£¼ì œ, í‚¤ì›Œë“œ, êµ¬ì¡°ì— ë¶€í•©í•˜ëŠ” ì ì ˆí•œ ì†Œì œëª©ë“¤ì¸ì§€ í‰ê°€í•˜ê³ , ì‚¬ìš©ìê°€ í™•ì • ì˜ì‚¬('ë„¤', 'ì¢‹ì•„ìš”', 'ì¢‹ìŠµë‹ˆë‹¤', 'ë‹¤ìŒ', 'ì§„í–‰' ë“±)ë¥¼ í‘œí˜„í–ˆëŠ”ì§€ ë¶„ì„í•˜ì„¸ìš”. í™•ì • ì˜ì‚¬ê°€ ìˆìœ¼ë©´ 'CONFIRMED'ë¥¼, ì—†ìœ¼ë©´ 'NEEDS_CONFIRMATION'ì„ ë°˜í™˜í•˜ì„¸ìš”.",
    }
    
    if step in prompts:
        try:
            response = model.generate_content(prompts[step])
            result = response.text.strip()
            return "CONFIRMED" in result
        except Exception as e:
            st.error(f"í™•ì¸ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False
    return False

# Gemini API í˜¸ì¶œ í•¨ìˆ˜
def ask_gemini(prompt):
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# ë‹¨ê³„ë³„ ì²˜ë¦¬ í•¨ìˆ˜
def process_step(step, user_input):
    if step == 1:  # ì£¼ì œ ì…ë ¥
        if st.session_state.waiting_for_input:
            context = "ì•„ì§ ì£¼ì œê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            prompt = react_prompt(context, "ê¸°ìˆ  ë¸”ë¡œê·¸ ì£¼ì œ ì…ë ¥ ìš”ì²­ ë° ì˜ë„ íŒŒì•…")
            response = ask_gemini(prompt)
            add_message("assistant", response)
            st.session_state.waiting_for_input = False
        else:
            confirmation = check_confirmation_prompt(step, user_input, st.session_state.messages)
            if confirmation:
                st.session_state.topic = user_input
                st.session_state.step = 2
                st.session_state.waiting_for_input = True
                # ì¶”ê°€ ì‘ë‹µìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
                next_prompt = react_prompt(f"ì£¼ì œ '{user_input}'ê°€ í™•ì •ë˜ì—ˆìŠµë‹ˆë‹¤.", "í‚¤ì›Œë“œ ì…ë ¥ ë‹¨ê³„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë„˜ì–´ê°€ì„¸ìš”.")
                response = ask_gemini(next_prompt)
                add_message("assistant", response)
            else:
                context = f"ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì£¼ì œ: {user_input}"
                prompt = react_prompt(context, "ì£¼ì œì— ëŒ€í•œ ì˜ê²¬ ì œì‹œ ë° í™•ì • ì§ˆë¬¸")
                response = ask_gemini(prompt)
                add_message("assistant", response)
    
    elif step == 2:  # í‚¤ì›Œë“œ ì…ë ¥
        if st.session_state.waiting_for_input:
            context = f"ì£¼ì œ: {st.session_state.topic}"
            prompt = react_prompt(context, "ì£¼ì œì— ì í•©í•œ í‚¤ì›Œë“œ ì¶”ì²œ ë° ì„ íƒ ìš”ì²­")
            response = ask_gemini(prompt)
            add_message("assistant", response)
            st.session_state.waiting_for_input = False
        else:
            confirmation = check_confirmation_prompt(step, user_input, st.session_state.messages)
            if confirmation:
                st.session_state.keywords = user_input
                st.session_state.step = 3
                st.session_state.waiting_for_input = True
                next_prompt = react_prompt(f"í‚¤ì›Œë“œ '{user_input}'ê°€ í™•ì •ë˜ì—ˆìŠµë‹ˆë‹¤.", "ê¸€ ìŠ¤íƒ€ì¼/ë…ìì¸µ ë‹¨ê³„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë„˜ì–´ê°€ì„¸ìš”.")
                response = ask_gemini(next_prompt)
                add_message("assistant", response)
            else:
                context = f"ì£¼ì œ: {st.session_state.topic}, ì‚¬ìš©ìê°€ ì œì•ˆí•œ í‚¤ì›Œë“œ: {user_input}"
                prompt = react_prompt(context, "ì œì•ˆëœ í‚¤ì›Œë“œì— ëŒ€í•œ í”¼ë“œë°± ë° í™•ì • ì§ˆë¬¸")
                response = ask_gemini(prompt)
                add_message("assistant", response)
    
    elif step == 3:  # ìŠ¤íƒ€ì¼/ë…ìì¸µ ì„ íƒ
        if st.session_state.waiting_for_input:
            context = f"ì£¼ì œ: {st.session_state.topic}, í‚¤ì›Œë“œ: {st.session_state.keywords}"
            prompt = react_prompt(context, "ê¸€ì˜ ëŒ€ìƒ ë…ìì¸µ ì§ˆë¬¸")
            response = ask_gemini(prompt)
            add_message("assistant", response)
            st.session_state.waiting_for_input = False
        else:
            confirmation = check_confirmation_prompt(step, user_input, st.session_state.messages)
            if confirmation:
                st.session_state.audience = user_input
                st.session_state.step = 4
                st.session_state.waiting_for_input = True
                next_prompt = react_prompt(f"ëŒ€ìƒ ë…ìì¸µ '{user_input}'ì´ í™•ì •ë˜ì—ˆìŠµë‹ˆë‹¤.", "ê¸€ êµ¬ì¡° ë‹¨ê³„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë„˜ì–´ê°€ì„¸ìš”.")
                response = ask_gemini(next_prompt)
                add_message("assistant", response)
            else:
                context = f"ì£¼ì œ: {st.session_state.topic}, í‚¤ì›Œë“œ: {st.session_state.keywords}, ì œì•ˆëœ ë…ìì¸µ: {user_input}"
                prompt = react_prompt(context, "ì œì•ˆëœ ë…ìì¸µì— ëŒ€í•œ í”¼ë“œë°± ë° í™•ì • ì§ˆë¬¸")
                response = ask_gemini(prompt)
                add_message("assistant", response)
    
    elif step == 4:  # ê¸€ êµ¬ì¡° ì„ íƒ
        if st.session_state.waiting_for_input:
            context = f"ì£¼ì œ: {st.session_state.topic}, í‚¤ì›Œë“œ: {st.session_state.keywords}, ë…ìì¸µ: {st.session_state.audience}"
            prompt = react_prompt(context, "ê¸€ì˜ êµ¬ì¡°ì— ëŒ€í•œ ì§ˆë¬¸")
            response = ask_gemini(prompt)
            add_message("assistant", response)
            st.session_state.waiting_for_input = False
        else:
            confirmation = check_confirmation_prompt(step, user_input, st.session_state.messages)
            if confirmation:
                st.session_state.structure = user_input
                st.session_state.step = 5
                st.session_state.waiting_for_input = True
                next_prompt = react_prompt(f"ê¸€ êµ¬ì¡° '{user_input}'ê°€ í™•ì •ë˜ì—ˆìŠµë‹ˆë‹¤.", "ì†Œì œëª© êµ¬ì„± ë‹¨ê³„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë„˜ì–´ê°€ì„¸ìš”.")
                response = ask_gemini(next_prompt)
                add_message("assistant", response)
            else:
                context = f"ì£¼ì œ: {st.session_state.topic}, í‚¤ì›Œë“œ: {st.session_state.keywords}, ë…ìì¸µ: {st.session_state.audience}, ì œì•ˆëœ êµ¬ì¡°: {user_input}"
                prompt = react_prompt(context, "ì œì•ˆëœ êµ¬ì¡°ì— ëŒ€í•œ ì§§ì€ ì˜ˆì‹œ ë° í™•ì • ì§ˆë¬¸")
                response = ask_gemini(prompt)
                add_message("assistant", response)
    
    elif step == 5:  # ì†Œì œëª© êµ¬ì„±
        if st.session_state.waiting_for_input:
            context = f"ì£¼ì œ: {st.session_state.topic}, í‚¤ì›Œë“œ: {st.session_state.keywords}, ë…ìì¸µ: {st.session_state.audience}, êµ¬ì¡°: {st.session_state.structure}"
            prompt = react_prompt(context, "ì†Œì œëª© ì œì•ˆ ë° ì‚¬ìš©ì ì˜ê²¬ ìš”ì²­")
            response = ask_gemini(prompt)
            add_message("assistant", response)
            st.session_state.waiting_for_input = False
        else:
            confirmation = check_confirmation_prompt(step, user_input, st.session_state.messages)
            if confirmation:
                st.session_state.headings = user_input
                st.session_state.step = 6
                st.session_state.waiting_for_input = True
                # ì†Œì œëª©ì´ í™•ì •ë˜ë©´ ë°”ë¡œ ì´ˆì•ˆ ì‘ì„± ë‹¨ê³„ë¡œ
                context = f"ì£¼ì œ: {st.session_state.topic}, í‚¤ì›Œë“œ: {st.session_state.keywords}, ë…ìì¸µ: {st.session_state.audience}, êµ¬ì¡°: {st.session_state.structure}, ì†Œì œëª©: {user_input}"
                prompt = react_prompt(context, "ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ê¸°ìˆ  ë¸”ë¡œê·¸ ì´ˆì•ˆ ì‘ì„±")
                add_message("assistant", "âœ¨ ì†Œì œëª©ì´ í™•ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ˆì•ˆì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤...")
                with st.spinner("ì´ˆì•ˆ ì‘ì„± ì¤‘..."):
                    draft = ask_gemini(prompt)
                st.session_state.draft = draft
                add_message("assistant", "ğŸ“ ì´ˆì•ˆì´ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
            else:
                context = f"ì£¼ì œ: {st.session_state.topic}, í‚¤ì›Œë“œ: {st.session_state.keywords}, ë…ìì¸µ: {st.session_state.audience}, êµ¬ì¡°: {st.session_state.structure}, ì œì•ˆëœ ì†Œì œëª©: {user_input}"
                prompt = react_prompt(context, "ì œì•ˆëœ ì†Œì œëª©ì— ëŒ€í•œ í”¼ë“œë°± ë° í™•ì • ì§ˆë¬¸")
                response = ask_gemini(prompt)
                add_message("assistant", response)
    
    elif step == 6:  # ì´ˆì•ˆ í‘œì‹œ ë° ìµœì¢… í”¼ë“œë°±
        if "draft_displayed" not in st.session_state or not st.session_state.draft_displayed:
            feedback_prompt = react_prompt(f"ë¸”ë¡œê·¸ ì´ˆì•ˆì´ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ë‚´ìš©: {st.session_state.draft[:200]}...", "ì‘ì„±ëœ ì´ˆì•ˆì— ëŒ€í•œ ê°„ëµí•œ ì„¤ëª… ë° í”¼ë“œë°± ìš”ì²­")
            feedback = ask_gemini(feedback_prompt)
            add_message("assistant", feedback)
            st.session_state.draft_displayed = True
        else:
            # ì‚¬ìš©ìì˜ ì¶”ê°€ í”¼ë“œë°± ì²˜ë¦¬
            context = f"ì‚¬ìš©ìì˜ í”¼ë“œë°±: {user_input}"
            prompt = react_prompt(context, "ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ìˆ˜ì • ìš”ì²­ì— ëŒ€í•œ ë‹µë³€")
            response = ask_gemini(prompt)
            add_message("assistant", response)

# UI ë° íë¦„ ì²˜ë¦¬
def run_app():
    st.title("ğŸ“ ê¸°ìˆ  ë¸”ë¡œê·¸ ì´ˆì•ˆ ì‘ì„± ì±—ë´‡")
    init_session()
    
    # ì‚¬ì´ë“œë°” - ì§„í–‰ ìƒí™©
    st.sidebar.title("ğŸ“Œ ì§„í–‰ ìƒí™©")
    steps = [
        "ì£¼ì œ ì…ë ¥", "í‚¤ì›Œë“œ ì„ íƒ", "ìŠ¤íƒ€ì¼ ì„ íƒ",
        "ê¸€ êµ¬ì¡° ì„ íƒ", "ì†Œì œëª© êµ¬ì„±", "ì´ˆì•ˆ ì‘ì„±"
    ]
    for i, s in enumerate(steps, 1):
        status = "âœ…" if i < st.session_state.step else ("ğŸŸ¡" if i == st.session_state.step else "âšª")
        st.sidebar.write(f"{status} {i}. {s}")
    
    # ë‹¤ì‹œ ì‹œì‘ ë²„íŠ¼
    if st.sidebar.button("ğŸ”„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.experimental_rerun()
    
    # ì´ˆê¸° ë©”ì‹œì§€ í‘œì‹œ
    if not st.session_state.messages:
        initial_message = "ì•ˆë…•í•˜ì„¸ìš”! ê¸°ìˆ  ë¸”ë¡œê·¸ ì´ˆì•ˆ ì‘ì„±ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì–´ë–¤ ì£¼ì œë¡œ ë¸”ë¡œê·¸ë¥¼ ì‘ì„±í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"
        add_message("assistant", initial_message)

    # ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì´ˆì•ˆì´ ìƒì„±ë˜ì—ˆë‹¤ë©´ ë³„ë„ í‘œì‹œ
    if st.session_state.step == 6 and st.session_state.draft:
        st.markdown("### ğŸ“„ ì‘ì„±ëœ ì´ˆì•ˆ")
        st.code(st.session_state.draft, language="markdown")
        st.download_button(
            label="ğŸ“¥ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ",
            data=st.session_state.draft,
            file_name="blog_draft.md",
            mime="text/markdown"
        )
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ë©”ì‹œì§€ ì…ë ¥..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("user"):
            st.markdown(prompt)
        # ë©”ì‹œì§€ ì €ì¥
        add_message("user", prompt)
        # í˜„ì¬ ë‹¨ê³„ì— ë§ëŠ” ì²˜ë¦¬
        process_step(st.session_state.step, prompt)
        
if __name__ == "__main__":
    run_app()

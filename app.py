import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from enum import Enum

# Step ìƒìˆ˜ ì •ì˜
class Step(Enum):
    TOPIC_QUESTION = "topic_question"
    TOPIC_CONFIRM = "topic_confirm"
    KEYWORD_QUESTION = "keyword_question"
    KEYWORD_CONFIRM = "keyword_confirm"
    STYLE_QUESTION = "style_question"
    STYLE_CONFIRM = "style_confirm"
    FLOW_SUGGEST = "flow_suggest"           # ìƒˆë¡œìš´ ë‹¨ê³„: ê¸€ íë¦„ ì œì•ˆ
    FLOW_CONFIRM = "flow_confirm"           # ìƒˆë¡œìš´ ë‹¨ê³„: ê¸€ íë¦„ í™•ì¸
    SECTION_EDIT = "section_edit"           # ìƒˆë¡œìš´ ë‹¨ê³„: ì„¹ì…˜ ìˆ˜ì •
    INTRO_WRITE = "intro_write"             # ìƒˆë¡œìš´ ë‹¨ê³„: ë„ì…ë¶€ ì‘ì„±
    INTRO_CONFIRM = "intro_confirm"         # ìƒˆë¡œìš´ ë‹¨ê³„: ë„ì…ë¶€ í™•ì¸
    SECTION_WRITE = "section_write"         # ìƒˆë¡œìš´ ë‹¨ê³„: ì„¹ì…˜ ì‘ì„±
    SECTION_CONFIRM = "section_confirm"     # ìƒˆë¡œìš´ ë‹¨ê³„: ì„¹ì…˜ í™•ì¸
    FULL_DRAFT = "full_draft"
    DONE = "done"

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Gemini API í‚¤ ì„¤ì •
genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
REACT_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ê¸°ìˆ  ë¸”ë¡œê·¸ ì‘ì„±ì„ ë„ì™€ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì…ë ¥ì„ ì´í•´í•˜ê³ , ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í†µí•´ ì‚¬ìš©ìê°€ ë¸”ë¡œê·¸ ê¸€ì„ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”.

ì‚¬ìš©ìì˜ ì˜ê²¬ê³¼ ìš”ì²­ì„ í•­ìƒ í™•ì¸í•˜ê³ , ëª¨í˜¸í•˜ê±°ë‚˜ ë¶ˆëª…í™•í•œ ë‚´ìš©ì€ ì¶”ê°€ ì§ˆë¬¸ì„ í†µí•´ ëª…í™•íˆ í•´ì£¼ì„¸ìš”.
ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ê¸° ì „ì— í•­ìƒ í˜„ì¬ ë‚´ìš©ì´ ë§ëŠ”ì§€ ì‚¬ìš©ìì—ê²Œ í™•ì¸ì„ ë°›ìœ¼ì„¸ìš”.

ë¸”ë¡œê·¸ ì‘ì„±ì€ ë‹¤ìŒ ìˆœì„œë¡œ ì§„í–‰ë©ë‹ˆë‹¤:
1. ì£¼ì œ íŒŒì•…í•˜ê¸°
2. í‚¤ì›Œë“œ ì¶”ì²œ ë° ì„ íƒí•˜ê¸°
3. ë¬¸ì²´ì™€ ìŠ¤íƒ€ì¼ ì„¤ì •í•˜ê¸°
4. ê¸€ì˜ íë¦„ ì œì•ˆí•˜ê¸°
5. ë„ì…ë¶€ ì‘ì„±í•˜ê¸°
6. ê° ì„¹ì…˜ ì‘ì„±í•˜ê¸°
7. ì „ì²´ ì´ˆì•ˆ í™•ì¸í•˜ê¸°

ê¸°ìˆ  ë¸”ë¡œê·¸ ì‘ì„± ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”:
- ê¸°ìˆ ì  ì •í™•ì„±ì„ ìœ ì§€í•˜ì„¸ìš”.
- ì‹¤ì œ ì‘ë™í•˜ëŠ” ì½”ë“œ ì˜ˆì œë¥¼ í¬í•¨í•˜ì„¸ìš”.
- ë‹¤ë¥¸ ê¸°ìˆ ì´ë‚˜ ì ‘ê·¼ë²•ê³¼ ë¹„êµ ë¶„ì„í•´ì£¼ì„¸ìš”.
- ì‹¤ë¬´ì—ì„œì˜ í™œìš© ì‚¬ë¡€ë¥¼ í¬í•¨í•˜ì„¸ìš”.
- ì´ì „ ì„¹ì…˜ê³¼ì˜ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ì„¸ìš”.

ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í†µí•´ ë‹¨ê³„ë³„ë¡œ ë¸”ë¡œê·¸ ì‘ì„±ì„ ë„ì™€ì£¼ì„¸ìš”.
ëª¨ë“  ì‘ë‹µì€ êµ¬ì¡°í™”ëœ í˜•ì‹(1, 2, 3 ë²ˆí˜¸ ë§¤ê¸°ê¸°)ì´ë‚˜ íŠ¹ìˆ˜ ì´ëª¨ì§€ ì—†ì´ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

# ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

PROMPT_TOPIC_QUESTION = """
ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ê¸°ìˆ  ë¸”ë¡œê·¸ ì´ˆì•ˆ ì‘ì„±ì„ ë„ì™€ë“œë¦¬ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. ğŸ˜Š
ë¨¼ì €, ì–´ë–¤ ì£¼ì œë¡œ ë¸”ë¡œê·¸ë¥¼ ì‘ì„±í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?
ê°„ë‹¨íˆ ë§ì”€í•´ ì£¼ì„¸ìš”.
"""

PROMPT_TOPIC_CONFIRM = """
ì œê°€ ì´í•´í•œ ì£¼ì œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:  
**"{inferred_topic}"**

ì´ ì£¼ì œë¡œ ë¸”ë¡œê·¸ë¥¼ ì‘ì„±í•˜ì‹œëŠ” ê²Œ ë§ì„ê¹Œìš”?
ë§ìœ¼ë©´ "ë„¤", ì•„ë‹ˆë©´ ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.
"""

PROMPT_KEYWORD_QUESTION = """
ì£¼ì œ "**{topic}**"ì™€ ê´€ë ¨í•´ì„œ ì•„ë˜ì™€ ê°™ì€ í‚¤ì›Œë“œë¥¼ ì¶”ì²œë“œë ¤ìš”:

ğŸ” ì¶”ì²œ í‚¤ì›Œë“œ:
{recommended_keywords}

ì´ ì¤‘ì—ì„œ ë‹¤ë£¨ê³  ì‹¶ì€ í‚¤ì›Œë“œë¥¼ **ë³µìˆ˜ë¡œ ì„ íƒ**í•´ì£¼ì‹œê³ ,
ì¶”ì²œ í‚¤ì›Œë“œì— ì—†ë”ë¼ë„ ì¶”ê°€í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œê°€ ìˆë‹¤ë©´ ììœ ë¡­ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”!
ì˜ˆ: "API, Mock ì„œë²„, ì‹¤ìŠµ ì˜ˆì œ"
"""

PROMPT_KEYWORD_CONFIRM = """
ì œê°€ ì´í•´í•œ ìµœì¢… í‚¤ì›Œë“œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:  
{selected_keywords}

ì´ í‚¤ì›Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ê¸€ì„ ì‘ì„±í•´ë„ ê´œì°®ì„ê¹Œìš”?
ìˆ˜ì •í•˜ê±°ë‚˜ ì¶”ê°€í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œê°€ ìˆë‹¤ë©´ ì•Œë ¤ì£¼ì„¸ìš”!
"""

PROMPT_STYLE_QUESTION = """
ì´ë²ˆì—” ë¸”ë¡œê·¸ì˜ ìŠ¤íƒ€ì¼ì„ ì •í•´ë³¼ê²Œìš”.
ì•„ë˜ëŠ” ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤:

- í˜•ì‹: íŠœí† ë¦¬ì–¼, ê¸°ìˆ  ë¦¬ë·°, ë¬¸ì œ í•´ê²° ì‚¬ë¡€
- ë¬¸ì²´: ì¹œê·¼í•œ, ê³µì‹ì ì¸, ì¤‘ë¦½ì 
- ë…ì ëŒ€ìƒ: ì´ˆë³´ì, ì¤‘ê¸‰ ê°œë°œì, ì „ë¬¸ê°€

ì˜ˆì‹œì—ì„œ ê³¨ë¼ë„ ì¢‹ê³ , ììœ ë¡­ê²Œ ì›í•˜ëŠ” ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±í•´ì£¼ì…”ë„ ê´œì°®ìŠµë‹ˆë‹¤.
ì˜ˆ: "íŠœí† ë¦¬ì–¼ í˜•ì‹, ì¹œê·¼í•œ í†¤, ì´ˆë³´ì ëŒ€ìƒ"
"""

PROMPT_STYLE_CONFIRM = """
ì œê°€ ì´í•´í•œ ìŠ¤íƒ€ì¼ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

- í˜•ì‹: **{format_style}**
- ë¬¸ì²´: **{tone}**
- ëŒ€ìƒ ë…ì: **{audience}**

ì´ ìŠ¤íƒ€ì¼ë¡œ ê¸€ì„ ì‘ì„±í•´ë„ ê´œì°®ì„ê¹Œìš”?
ììœ ë¡­ê²Œ ìˆ˜ì •í•˜ê±°ë‚˜ ì¶”ê°€í•˜ê³  ì‹¶ì€ ìš”ì†Œê°€ ìˆë‹¤ë©´ ë§ì”€í•´ì£¼ì„¸ìš”.
"""

PROMPT_FLOW_SUGGEST = """
ìœ„ì˜ ì£¼ì œ, í‚¤ì›Œë“œ, ìŠ¤íƒ€ì¼ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ì™€ ê°™ì€ ê¸€ íë¦„ì„ ì œì•ˆë“œë ¤ìš”:

ğŸ“ ì œì•ˆëœ íë¦„:
{suggested_flow}

ì´ íë¦„ì€ ì°¸ê³ ìš©ì´ë‹ˆ, ë§ˆìŒê» ìˆ˜ì •í•˜ì…”ë„ ì¢‹ì•„ìš”!
ì„¹ì…˜ì„ ì¶”ê°€í•˜ê±°ë‚˜ ìˆœì„œë¥¼ ë°”ê¾¸ê³  ì‹¶ìœ¼ì‹œë©´ ì•Œë ¤ì£¼ì„¸ìš”.
"""

PROMPT_FLOW_CONFIRM = """
ì•„ë˜ëŠ” ê° ì„¹ì…˜ì˜ íë¦„ì…ë‹ˆë‹¤:

íë¦„ ëª©ë¡:
{finalized_flow}

ì´ íë¦„ëŒ€ë¡œ ê¸€ì„ ì‘ì„±í•´ë„ ê´œì°®ì„ê¹Œìš”?
ìˆ˜ì •í•˜ê±°ë‚˜ ì¶”ê°€í•˜ê³  ì‹¶ì€ í•­ëª©ì´ ìˆë‹¤ë©´ ë§ì”€í•´ì£¼ì„¸ìš”!
"""

PROMPT_SECTION_EDIT = """
ì„¹ì…˜ "{section_title}"ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì€ ìˆ˜ì •ì„ ì œì•ˆí•´ë“œë¦´ê²Œìš”:

```
{suggested_changes}
```

ì´ ìˆ˜ì •ì´ ë§ˆìŒì— ë“œì‹œë‚˜ìš”?
ìˆ˜ì •í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‘ì„±í•˜ê³  ì‹¶ìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”!
"""

PROMPT_INTRO_WRITE = """
ì´ ê¸€ì˜ ì„œë¡  ë¶€ë¶„ì¸ "{section_title}"ì— ëŒ€í•œ ì´ˆì•ˆì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ ìš”ì†Œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
1. ì£¼ì œì— ëŒ€í•œ ê°„ê²°í•œ ì†Œê°œì™€ ì¤‘ìš”ì„±
2. ë…ìê°€ ì´ ê¸€ì„ ì½ì–´ì•¼ í•˜ëŠ” ì´ìœ 
3. ê¸€ì—ì„œ ë‹¤ë£° ë‚´ìš©ì— ëŒ€í•œ ê°„ëµí•œ ê°œìš”
4. ë…ìì˜ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆëŠ” í¥ë¯¸ë¡œìš´ ì‹œì‘ì 

ì£¼ì œ: {topic}
í‚¤ì›Œë“œ: {keywords}
ìŠ¤íƒ€ì¼: {style}
"""

PROMPT_INTRO_CONFIRM = """
ì œê°€ ì´í•´í•œ ë„ì…ë¶€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```
{intro_content}
```

ì´ ë„ì…ë¶€ë¡œ ê¸€ì„ ì‘ì„±í•´ë„ ê´œì°®ì„ê¹Œìš”?
ìˆ˜ì •í•˜ê±°ë‚˜ ì¶”ê°€í•˜ê³  ì‹¶ì€ ìš”ì†Œê°€ ìˆë‹¤ë©´ ë§ì”€í•´ì£¼ì„¸ìš”.
"""

PROMPT_SECTION_WRITE = """
ì´ ê¸€ì˜ ë³¸ë¬¸ ë¶€ë¶„ì¸ "{section_title}"ì— ëŒ€í•œ ì´ˆì•ˆì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ ìš”ì†Œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
1. í•´ë‹¹ ì„¹ì…˜ì˜ í•µì‹¬ ê°œë… ì„¤ëª…
2. ì‹¤ì œ ì‘ë™í•˜ëŠ” ì½”ë“œ ì˜ˆì œì™€ ì„¤ëª…
3. ë‹¤ë¥¸ ì ‘ê·¼ë²•ê³¼ì˜ ë¹„êµ ë¶„ì„
4. ì‹¤ë¬´ ì ìš© ì‚¬ë¡€ ë˜ëŠ” ì˜ˆì‹œ

ì´ì „ ì„¹ì…˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ì„¸ìš”:
{previous_sections}

ì£¼ì œ: {topic}
í‚¤ì›Œë“œ: {keywords}
ìŠ¤íƒ€ì¼: {style}
"""

PROMPT_SECTION_CONFIRM = """
ì œê°€ ì´í•´í•œ ì„¹ì…˜ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```
{section_content}
```

ì´ ì„¹ì…˜ìœ¼ë¡œ ì§„í–‰í•´ë„ ê´œì°®ì„ê¹Œìš”?
ìˆ˜ì •í•˜ê±°ë‚˜ ì¶”ê°€í•˜ê³  ì‹¶ì€ ìš”ì†Œê°€ ìˆë‹¤ë©´ ë§ì”€í•´ì£¼ì„¸ìš”.
"""

# ìˆ˜ì • ìš”ì²­ì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸
PROMPT_REVISION = """
ë‹¤ìŒ ì„¹ì…˜ì˜ ì´ˆì•ˆì„ ìˆ˜ì •í•´ì£¼ì„¸ìš”:
ì„¹ì…˜ ì œëª©: {section_title}

ì‚¬ìš©ì ìš”ì²­: {user_request}

ê¸°ì¡´ ì´ˆì•ˆ:
{original_draft}

ì´ì „ ì„¹ì…˜ ë‚´ìš©:
{previous_sections}

ìˆ˜ì • ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”:
1. ì‚¬ìš©ìì˜ ìš”ì²­ì‚¬í•­ì„ ì •í™•íˆ ë°˜ì˜í•´ì£¼ì„¸ìš”.
2. ê¸°ìˆ ì  ì •í™•ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
3. ê¸€ì˜ ì „ì²´ì ì¸ íë¦„ê³¼ ì¼ê´€ì„±ì„ ìœ ì§€í•´ì£¼ì„¸ìš”.
4. ì½”ë“œ ì˜ˆì œê°€ ìˆë‹¤ë©´ ì •í™•í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•˜ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.
5. ê¸°ì¡´ ì´ˆì•ˆì˜ ì¢‹ì€ ë¶€ë¶„ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•´ì£¼ì„¸ìš”.
6. ì‚¬ìš©ìê°€ íŠ¹ì • ë¶€ë¶„ë§Œ ìˆ˜ì •ì„ ìš”ì²­í–ˆë‹¤ë©´, ê·¸ ë¶€ë¶„ë§Œ ìˆ˜ì •í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ê·¸ëŒ€ë¡œ ë‘ì„¸ìš”.

ì£¼ì œ: {topic}
í‚¤ì›Œë“œ: {keywords}
ìŠ¤íƒ€ì¼: {style}

ìˆ˜ì •ëœ ë‚´ìš©ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

# Gemini ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
def get_chat_model():
    return genai.GenerativeModel("gemini-1.5-pro")

# ì „ì²´ ì´ˆì•ˆ í‘œì‹œ í•¨ìˆ˜
def show_full_draft():
    subtitles = st.session_state.collected.get("finalized_flow", [])
    full_draft = ""
    
    # ì œëª© ìƒì„±
    topic = st.session_state.collected.get('user_topic', '')
    full_draft += f"# {topic}\n\n"
    
    # ê° ì„¹ì…˜ ë‚´ìš© í•©ì¹˜ê¸°
    for subtitle in subtitles:
        content = st.session_state.generated_drafts.get(subtitle, "")
        full_draft += f"## {subtitle}\n{content}\n\n"
    
    # ì „ì²´ ì´ˆì•ˆì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    st.session_state.full_draft = full_draft
    
    # ì „ì²´ ì´ˆì•ˆ í‘œì‹œ
    st.session_state.step = Step.DONE.value
    bot_say(f"ëª¨ë“  ì´ˆì•ˆ ì‘ì„±ì„ ì™„ë£Œí–ˆì–´ìš”! ì•„ë˜ëŠ” ì „ì²´ ì´ˆì•ˆì…ë‹ˆë‹¤:")
    
    # ë³µì‚¬ ê°€ëŠ¥í•œ ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ ì „ì²´ ì´ˆì•ˆ í‘œì‹œ
    with st.expander("ğŸ“‹ ì „ì²´ ì´ˆì•ˆ (í´ë¦­í•˜ì—¬ ë³µì‚¬í•˜ê¸°)", expanded=True):
        st.code(full_draft, language="markdown")
        st.info("ìœ„ ì½”ë“œ ë¸”ë¡ì„ í´ë¦­í•˜ë©´ ì „ì²´ ë‚´ìš©ì„ ë³µì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    bot_say("í•„ìš”í•œ ê²½ìš° ìˆ˜ì •í•˜ê±°ë‚˜ ë³µì‚¬í•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”. 'ì „ì²´ ì´ˆì•ˆ ë³´ê¸°'ë¼ê³  ì…ë ¥í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë‹¤ì‹œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ì±—ë´‡ ë©”ì‹œì§€ ì „ì†¡ í•¨ìˆ˜
def bot_say(message):
    st.session_state.messages.append({"role": "assistant", "content": message})
    st.session_state.is_typing = False
    st.session_state.processed = True
    # ë©”ì‹œì§€ëŠ” ë©”ì‹œì§€ ì¶œë ¥ ë£¨í”„ì—ì„œ í‘œì‹œë¨

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜
def user_say():
    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.session_state.is_typing = True
        st.session_state.processed = False

# AI ëª¨ë¸ì— ìš”ì²­í•˜ê³  ì‘ë‹µ ë°›ëŠ” ê³µí†µ í•¨ìˆ˜
def process_model_request(prompt):
    try:
        model = get_chat_model()
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        error_msg = f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        return error_msg

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ í•µì‹¬ í•¨ìˆ˜
def handle_input(user_input):
    # ë‹¨ê³„ë³„ ì²˜ë¦¬ ë¡œì§
    step = st.session_state.step
    user_input_lower = user_input.lower()
    
    # 'ì „ì²´ ì´ˆì•ˆ ë³´ê¸°' ìš”ì²­ ì²˜ë¦¬
    if any(word in user_input_lower for word in ["ì „ì²´ ì´ˆì•ˆ", "ëª¨ë“  ì´ˆì•ˆ", "ì „ì²´ ë‚´ìš©", "ê²°ê³¼ ë³´ê¸°"]):
        if hasattr(st.session_state, 'full_draft') and st.session_state.full_draft:
            st.session_state.step = Step.DONE.value
            bot_say("ë„¤, ì „ì²´ ì´ˆì•ˆì„ ë‹¤ì‹œ ë³´ì—¬ë“œë¦´ê²Œìš”:")
            with st.expander("ğŸ“‹ ì „ì²´ ì´ˆì•ˆ (í´ë¦­í•˜ì—¬ ë³µì‚¬í•˜ê¸°)", expanded=True):
                st.code(st.session_state.full_draft, language="markdown")
                st.info("ìœ„ ì½”ë“œ ë¸”ë¡ì„ í´ë¦­í•˜ë©´ ì „ì²´ ë‚´ìš©ì„ ë³µì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return
        else:
            bot_say("ì•„ì§ ì „ì²´ ì´ˆì•ˆì´ ì‘ì„±ë˜ì§€ ì•Šì•˜ì–´ìš”. ëª¨ë“  ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ë©´ ì „ì²´ ì´ˆì•ˆì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return

    # ë„ì…ë¶€ í™•ì¸ ë‹¨ê³„
    if step == Step.INTRO_CONFIRM.value:
        # ìˆ˜ì • ìš”ì²­ì´ ìˆëŠ”ì§€ í™•ì¸
        if any(word in user_input_lower for word in ["ìˆ˜ì •", "ë°”ê¿”", "ë‹¤ì‹œ", "ë‹¤ë¥¸", "ë³€ê²½", "ê³ ì¹˜", "ì•„ë‹ˆ"]):
            section_title = st.session_state.current_section
            original_draft = st.session_state.draft_section_content
            prompt = PROMPT_REVISION.format(
                section_title=section_title,
                user_request=user_input,
                original_draft=original_draft,
                previous_sections="",
                topic=st.session_state.collected.get('user_topic', ''),
                keywords=", ".join(st.session_state.collected.get('user_keywords', [])),
                style=f"{st.session_state.collected.get('format_style', '')} / {st.session_state.collected.get('tone', '')} / {st.session_state.collected.get('audience', '')}"
            )
            bot_say("ë„¤, ë„ì…ë¶€ë¥¼ ìˆ˜ì •í•´ë³¼ê²Œìš”...")
            revised_content = process_model_request(prompt)
            st.session_state.draft_section_content = revised_content
            confirm_message = PROMPT_INTRO_CONFIRM.format(intro_content=revised_content)
            bot_say(confirm_message)
            return
            
        # ì§„í–‰ ì˜ì‚¬ê°€ ìˆëŠ”ì§€ í™•ì¸
        if any(word in user_input_lower for word in ["ë„¤", "ì¢‹ì•„", "ê´œì°®", "ì§„í–‰", "ì‹œì‘", "ë‹¤ìŒ"]):
            section_title = st.session_state.current_section
            section_content = st.session_state.draft_section_content
            st.session_state.generated_drafts[section_title] = section_content
            flow_items = st.session_state.collected.get("finalized_flow", [])
            current_index = flow_items.index(section_title)
            if current_index < len(flow_items) - 1:
                next_section = flow_items[current_index + 1]
                st.session_state.current_section = next_section
                previous_sections = []
                for i in range(current_index + 1):
                    prev_title = flow_items[i]
                    prev_content = st.session_state.generated_drafts.get(prev_title, "")
                    if prev_content:
                        previous_sections.append(f"## {prev_title}\n{prev_content}")
                previous_sections_text = "\n\n".join(previous_sections)
                prompt = PROMPT_SECTION_WRITE.format(
                    section_title=next_section,
                    previous_sections=previous_sections_text,
                    topic=st.session_state.collected.get('user_topic', ''),
                    keywords=", ".join(st.session_state.collected.get('user_keywords', [])),
                    style=f"{st.session_state.collected.get('format_style', '')} / {st.session_state.collected.get('tone', '')} / {st.session_state.collected.get('audience', '')}"
                )
                st.session_state.step = Step.SECTION_WRITE.value
                bot_say(f"ì´ì œ '{next_section}' ì„¹ì…˜ì„ ì‘ì„±í•´ë³¼ê²Œìš”...")
                section_content = process_model_request(prompt)
                st.session_state.draft_section_content = section_content
                st.session_state.step = Step.SECTION_CONFIRM.value
                confirm_message = PROMPT_SECTION_CONFIRM.format(section_content=section_content)
                bot_say(confirm_message)
                return
            else:
                show_full_draft()
                return
        bot_say("""ë„ì…ë¶€ì— ëŒ€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ì‹œë‚˜ìš”?
- ì§„í–‰í•˜ì‹œë ¤ë©´ 'ë„¤', 'ì¢‹ì•„ìš”', 'ì§„í–‰í• ê²Œìš”'ë¼ê³  ë§ì”€í•´ì£¼ì„¸ìš”.
- ìˆ˜ì •ì´ í•„ìš”í•˜ì‹œë‹¤ë©´ 'ìˆ˜ì •', 'ë‹¤ì‹œ', 'ë°”ê¿”' ë“±ì˜ ë§ì”€ì„ í•´ì£¼ì„¸ìš”.""")
        return

    # ... rest of the handle_input function ...

# ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.step = Step.TOPIC_QUESTION.value
    st.session_state.collected = {}
    st.session_state.generated_drafts = {}
    st.session_state.draft_index = 0

# íƒ€ì´í•‘ ì¸ë””ì¼€ì´í„°ë¥¼ ìœ„í•œ ìƒíƒœ
if "is_typing" not in st.session_state:
    st.session_state.is_typing = False
    st.session_state.processed = True

# ì±— UI
st.title("ğŸ§  ê¸°ìˆ  ë¸”ë¡œê·¸ ì´ˆì•ˆ ìƒì„± ì±—ë´‡")
st.markdown("---")

# CSS ì• ë‹ˆë©”ì´ì…˜ ì¶”ê°€ - ì±—ë´‡ ì‘ì„±ì¤‘ ì• ë‹ˆë©”ì´ì…˜
st.markdown("""
<style>
@keyframes bounce-dots {
    0%, 20% { transform: translateY(0); }
    50% { transform: translateY(-4px); }
    80%, 100% { transform: translateY(0); }
}

.typing-indicator {
    color: #888888;
    font-size: 14px;
    padding: 8px 12px;
    border-radius: 18px;
    background-color: #f1f1f1;
    display: inline-flex;
    align-items: center;
    margin-bottom: 5px;
}

.typing-text {
    font-style: italic;
}

.dots {
    display: flex;
    margin-left: 5px;
}

.dot {
    width: 6px;
    height: 6px;
    border-radius: 50%;
    background-color: #888888;
    margin: 0 1px;
    display: inline-block;
    animation: bounce-dots 1.5s infinite;
}

.dot:nth-child(2) {
    animation-delay: 0.2s;
}

.dot:nth-child(3) {
    animation-delay: 0.4s;
}

/* ë‹¨ê³„ í‘œì‹œ ìŠ¤íƒ€ì¼ */
.step-current {
    margin-left: 0px; 
    padding: 5px 10px; 
    background-color: #E6F0FF; 
    color: #0066CC; 
    font-weight: bold; 
    font-size: 16px;
    border-radius: 5px;
    margin-bottom: 5px;
}

.step-other {
    padding: 5px 10px;
    margin-bottom: 5px; 
    color: #555555;
}
</style>
""", unsafe_allow_html=True)

# ì‚¬ì´ë“œë°” ì§„í–‰ ë‹¨ê³„ í‘œì‹œ
with st.sidebar:
    st.markdown("### ğŸ§­ ì§„í–‰ ë‹¨ê³„")
    steps = [
        ("topic", "1. ì£¼ì œ ì…ë ¥"),
        ("keyword", "2. í‚¤ì›Œë“œ ì„ íƒ"),
        ("style", "3. ìŠ¤íƒ€ì¼ ì„¤ì •"),
        ("flow", "4. ê¸€ íë¦„ ì œì•ˆ"),
        ("intro", "5. ë„ì…ë¶€ ì‘ì„±"),
        ("section", "6. ì„¹ì…˜ ì‘ì„±"),
        ("full_draft", "7. ì „ì²´ ì´ˆì•ˆ í™•ì¸")
    ]
    
    # í˜„ì¬ ë‹¨ê³„ì— í•´ë‹¹í•˜ëŠ” prefix ì°¾ê¸°
    current_step = st.session_state.step
    current_prefix = ""
    
    # ë‹¨ê³„ë³„ prefix ë§¤í•‘
    step_prefix_map = {
        Step.TOPIC_QUESTION.value: "topic",
        Step.TOPIC_CONFIRM.value: "topic",
        Step.KEYWORD_QUESTION.value: "keyword",
        Step.KEYWORD_CONFIRM.value: "keyword",
        Step.STYLE_QUESTION.value: "style",
        Step.STYLE_CONFIRM.value: "style",
        Step.FLOW_SUGGEST.value: "flow",
        Step.FLOW_CONFIRM.value: "flow",
        Step.INTRO_WRITE.value: "intro",
        Step.INTRO_CONFIRM.value: "intro",
        Step.SECTION_WRITE.value: "section",
        Step.SECTION_CONFIRM.value: "section",
        Step.SECTION_EDIT.value: "section",
        Step.FULL_DRAFT.value: "full_draft",
        Step.DONE.value: "full_draft"
    }
    
    current_prefix = step_prefix_map.get(current_step, "")
    
    # ê° ë‹¨ê³„ í‘œì‹œ
    for key, label in steps:
        if key == current_prefix:
            st.markdown(f'<div class="step-current">â†’ {label}</div>', unsafe_allow_html=True)
        else:
            st.markdown(f'<div class="step-other">{label}</div>', unsafe_allow_html=True)

# ë©”ì‹œì§€ ì¶œë ¥
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì±—ë´‡ íƒ€ì´í•‘ ì¸ë””ì¼€ì´í„° í‘œì‹œ
if st.session_state.is_typing:
    with st.chat_message("assistant"):
        st.markdown('<div class="typing-indicator"><span class="typing-text">ì±—ë´‡ì´ ì‘ì„±í•˜ê³  ìˆì–´ìš”</span><span class="dots"><span class="dot"></span><span class="dot"></span><span class="dot"></span></span></div>', unsafe_allow_html=True)

# ì¸ì‚¿ë§ì´ ì—†ëŠ” ê²½ìš° ì²« ë©”ì‹œì§€ í‘œì‹œ (ì„¸ì…˜ ì‹ ê·œ ì‹œì‘ ë˜ëŠ” ë¸Œë¼ìš°ì € ìƒˆë¡œê³ ì¹¨ ì‹œ)
if len(st.session_state.messages) == 0:
    with st.chat_message("assistant"):
        st.markdown(PROMPT_TOPIC_QUESTION)
    st.session_state.messages.append({"role": "assistant", "content": PROMPT_TOPIC_QUESTION})
    st.session_state.step = Step.TOPIC_QUESTION.value

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¦‰ì‹œ ì¶”ê°€ ë° í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.session_state.is_typing = True
    st.session_state.processed = False
    
    # ë©”ì‹œì§€ ì²˜ë¦¬
    handle_input(prompt)

def handle_section_revision(section_title, user_request, original_draft):
    # ì´ì „ ì„¹ì…˜ ë‚´ìš© ìˆ˜ì§‘
    previous_sections = []
    flow_items = st.session_state.collected.get("finalized_flow", [])
    current_index = flow_items.index(section_title)
    
    for i in range(current_index):
        prev_title = flow_items[i]
        prev_content = st.session_state.generated_drafts.get(prev_title, "")
        if prev_content:
            previous_sections.append(f"## {prev_title}\n{prev_content}")
    
    previous_sections_text = "\n\n".join(previous_sections)
    
    # ìˆ˜ì • í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = PROMPT_REVISION.format(
        section_title=section_title,
        user_request=user_request,
        original_draft=original_draft,
        previous_sections=previous_sections_text,
        topic=st.session_state.collected.get('user_topic', ''),
        keywords=", ".join(st.session_state.collected.get('user_keywords', [])),
        style=f"{st.session_state.collected.get('format_style', '')} / {st.session_state.collected.get('tone', '')} / {st.session_state.collected.get('audience', '')}"
    )
    
    # ìˆ˜ì •ëœ ë‚´ìš© ìƒì„±
    revised_content = process_model_request(prompt)
    if revised_content:
        st.session_state.draft_section_content = revised_content
        return True
    return False
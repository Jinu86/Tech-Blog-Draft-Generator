import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from enum import Enum

# Step ìƒìˆ˜ ì •ì˜
class Step(Enum):
    TOPIC_QUESTION = "topic_question"
    TOPIC_CONFIRM = "topic_confirm"
    KEYWORD_QUESTION = "keyword_question"
    KEYWORD_CONFIRM = "keyword_confirm"
    STYLE_QUESTION = "style_question"
    STYLE_CONFIRM = "style_confirm"
    STRUCTURE_SUGGEST = "structure_suggest"
    STRUCTURE_CONFIRM = "structure_confirm"
    SUBTITLE_CONFIRM = "subtitle_confirm"
    DRAFT_GENERATE = "draft_generate"
    DRAFT_CONFIRM = "draft_confirm"
    FULL_DRAFT = "full_draft"
    DONE = "done"

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Gemini API í‚¤ ì„¤ì •
genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
REACT_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ê¸°ìˆ  ë¸”ë¡œê·¸ ì‘ì„±ì„ ë„ì™€ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì€ ReAct ë°©ì‹(Reasoning + Acting)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
ê° ë‹¨ê³„ì—ì„œ ì‚¬ìš©ìì˜ ì…ë ¥ì„ í•´ì„í•˜ê³ , ë‹¹ì‹ ì´ ì´í•´í•œ ë‚´ìš©ì´ ë§ëŠ”ì§€ ë‹¤ì‹œ ë¬¼ì–´ë³¸ í›„ ì‚¬ìš©ì í™•ì¸ì„ ë°›ì€ ë‹¤ìŒì—ë§Œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.

ì‚¬ìš©ì ì…ë ¥ì´ ëª¨í˜¸í•˜ê±°ë‚˜ ë¶ˆëª…í™•í•  ê²½ìš° ë°˜ë“œì‹œ ëª…í™•í•˜ê²Œ ë‹¤ì‹œ ë¬¼ì–´ë³´ì„¸ìš”.
ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ì§€ ë§ê³ , ë°˜ë“œì‹œ í™•ì¸í•˜ì„¸ìš”.

ì§„í–‰ ìˆœì„œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
1. [ì£¼ì œ íŒŒì•…]
2. [í‚¤ì›Œë“œ ì¶”ì²œ ë° ì„ íƒ]
3. [ë¬¸ì²´/ëŒ€ìƒ ìŠ¤íƒ€ì¼ ì„ íƒ]
4. [ê¸€ì˜ êµ¬ì¡° ì œì•ˆ ë° í™•ì •]
5. [ì†Œì œëª© ë° íë¦„ êµ¬ì„±]
6. [ì´ˆì•ˆ ì‘ì„±]

ê° ë‹¨ê³„ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ íŒ¨í„´ì„ ë”°ë¥´ì„¸ìš”:
- ğŸ§ Reasoning: ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¹ì‹ ì´ ì´í•´í•œ ë‚´ìš©ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
- âš™ï¸ Acting: ì´í•´í•œ ë‚´ìš©ì„ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ê³ , ë§ëŠ”ì§€ ë¬¼ì–´ë´…ë‹ˆë‹¤.
- âœ… ì‚¬ìš©ì í™•ì¸ ì´í›„ì—ë§Œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ì„¸ìš”.

ê¸°ìˆ  ë¸”ë¡œê·¸ ì‘ì„± ì‹œ ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¥´ì„¸ìš”:
1. ê¸°ìˆ ì  ì •í™•ì„±: ëª¨ë“  ê¸°ìˆ  ì •ë³´ì™€ ê°œë… ì„¤ëª…ì€ ì •í™•í•´ì•¼ í•©ë‹ˆë‹¤.
2. ì½”ë“œ ì˜ˆì œ: ì‹¤ì œ ì‘ë™í•˜ëŠ” ì½”ë“œ ì˜ˆì œë¥¼ í¬í•¨í•˜ê³ , ê° ë¶€ë¶„ì— ëŒ€í•œ ì„¤ëª…ì„ ì¶”ê°€í•˜ì„¸ìš”.
3. ë¹„êµ ë¶„ì„: ë‹¤ë¥¸ ê¸°ìˆ ì´ë‚˜ ì ‘ê·¼ë²•ê³¼ ë¹„êµí•˜ì—¬ ì¥ë‹¨ì ì„ ì œì‹œí•˜ì„¸ìš”.
4. ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€: ì‹¤ë¬´ì—ì„œ ì–´ë–»ê²Œ í™œìš©ë  ìˆ˜ ìˆëŠ”ì§€ êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì„¸ìš”.
5. ì¼ê´€ì„±: ì´ì „ì— ì‘ì„±ëœ ì„¹ì…˜ì˜ ë‚´ìš©ê³¼ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ì„¸ìš”.
"""

# ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

PROMPT_TOPIC_QUESTION = """
ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ê¸°ìˆ  ë¸”ë¡œê·¸ ì´ˆì•ˆ ì‘ì„±ì„ ë„ì™€ë“œë¦¬ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. ğŸ˜Š
ë¨¼ì €, ì–´ë–¤ ì£¼ì œë¡œ ë¸”ë¡œê·¸ë¥¼ ì‘ì„±í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?
ê°„ë‹¨íˆ ë§ì”€í•´ ì£¼ì„¸ìš”.
"""

PROMPT_TOPIC_CONFIRM = """
ğŸ§ ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ì œê°€ ì´í•´í•œ ì£¼ì œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:  
**"{inferred_topic}"**

âš™ï¸ ì´ ì£¼ì œë¡œ ë¸”ë¡œê·¸ë¥¼ ì‘ì„±í•˜ì‹œëŠ” ê²Œ ë§ì„ê¹Œìš”?
ë§ìœ¼ë©´ "ë„¤", ì•„ë‹ˆë©´ ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.
"""

PROMPT_KEYWORD_QUESTION = """
ì£¼ì œ "**{topic}**"ì™€ ê´€ë ¨í•´ì„œ ì•„ë˜ì™€ ê°™ì€ í‚¤ì›Œë“œë¥¼ ì¶”ì²œë“œë ¤ìš”:

ğŸ” ì¶”ì²œ í‚¤ì›Œë“œ:
{recommended_keywords}

ì´ ì¤‘ì—ì„œ ë‹¤ë£¨ê³  ì‹¶ì€ í‚¤ì›Œë“œë¥¼ **ë³µìˆ˜ë¡œ ì„ íƒ**í•´ì£¼ì‹œê³ ,
ì¶”ì²œ í‚¤ì›Œë“œì— ì—†ë”ë¼ë„ ì¶”ê°€í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œê°€ ìˆë‹¤ë©´ ììœ ë¡­ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”!
ì˜ˆ: "API, Mock ì„œë²„, ì‹¤ìŠµ ì˜ˆì œ"
"""

PROMPT_KEYWORD_CONFIRM = """
ğŸ§ ì œê°€ ì´í•´í•œ ìµœì¢… í‚¤ì›Œë“œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:  
{selected_keywords}

âš™ï¸ ì´ í‚¤ì›Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ê¸€ì„ ì‘ì„±í•´ë„ ê´œì°®ì„ê¹Œìš”?
ìˆ˜ì •í•˜ê±°ë‚˜ ì¶”ê°€í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œê°€ ìˆë‹¤ë©´ ì•Œë ¤ì£¼ì„¸ìš”!
"""

PROMPT_STYLE_QUESTION = """
ì´ë²ˆì—” ë¸”ë¡œê·¸ì˜ ìŠ¤íƒ€ì¼ì„ ì •í•´ë³¼ê²Œìš”.
ì•„ë˜ëŠ” ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤:

- í˜•ì‹: íŠœí† ë¦¬ì–¼, ê¸°ìˆ  ë¦¬ë·°, ë¬¸ì œ í•´ê²° ì‚¬ë¡€
- ë¬¸ì²´: ì¹œê·¼í•œ, ê³µì‹ì ì¸, ì¤‘ë¦½ì 
- ë…ì ëŒ€ìƒ: ì´ˆë³´ì, ì¤‘ê¸‰ ê°œë°œì, ì „ë¬¸ê°€

ì˜ˆì‹œì—ì„œ ê³¨ë¼ë„ ì¢‹ê³ , ììœ ë¡­ê²Œ ì›í•˜ëŠ” ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±í•´ì£¼ì…”ë„ ê´œì°®ìŠµë‹ˆë‹¤.
ì˜ˆ: "íŠœí† ë¦¬ì–¼ í˜•ì‹, ì¹œê·¼í•œ í†¤, ì´ˆë³´ì ëŒ€ìƒ"
"""

PROMPT_STYLE_CONFIRM = """
ğŸ§ ì œê°€ ì´í•´í•œ ìŠ¤íƒ€ì¼ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

- í˜•ì‹: **{format_style}**
- ë¬¸ì²´: **{tone}**
- ëŒ€ìƒ ë…ì: **{audience}**

âš™ï¸ ì´ ìŠ¤íƒ€ì¼ë¡œ ê¸€ì„ ì‘ì„±í•´ë„ ê´œì°®ì„ê¹Œìš”?
ììœ ë¡­ê²Œ ìˆ˜ì •í•˜ê±°ë‚˜ ì¶”ê°€í•˜ê³  ì‹¶ì€ ìš”ì†Œê°€ ìˆë‹¤ë©´ ë§ì”€í•´ì£¼ì„¸ìš”.
"""

PROMPT_STRUCTURE_SUGGEST = """
ìœ„ì˜ ì£¼ì œ, í‚¤ì›Œë“œ, ìŠ¤íƒ€ì¼ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ì™€ ê°™ì€ ê¸€ êµ¬ì¡°ë¥¼ ì œì•ˆë“œë ¤ìš”:

ğŸ“ ì œì•ˆëœ êµ¬ì¡°:
{suggested_structure}

âš™ï¸ ì´ êµ¬ì¡°ëŠ” ì°¸ê³ ìš©ì´ë‹ˆ, ë§ˆìŒê» ìˆ˜ì •í•˜ì…”ë„ ì¢‹ì•„ìš”!
ì„¹ì…˜ì„ ì¶”ê°€í•˜ê±°ë‚˜ ìˆœì„œë¥¼ ë°”ê¾¸ê³  ì‹¶ìœ¼ì‹œë©´ ì•Œë ¤ì£¼ì„¸ìš”.
"""

PROMPT_SUBTITLES_CONFIRM = """
ì•„ë˜ëŠ” ê° ì„¹ì…˜ì˜ ì†Œì œëª©ì…ë‹ˆë‹¤:

ğŸ“Œ ì†Œì œëª© ëª©ë¡:
{finalized_subtitles}

âš™ï¸ ì´ íë¦„ëŒ€ë¡œ ê¸€ì„ ì‘ì„±í•´ë„ ê´œì°®ì„ê¹Œìš”?
ìˆ˜ì •í•˜ê±°ë‚˜ ì¶”ê°€í•˜ê³  ì‹¶ì€ í•­ëª©ì´ ìˆë‹¤ë©´ ë§ì”€í•´ì£¼ì„¸ìš”!
"""

PROMPT_DRAFT_SECTION = """
âœï¸ ì„¹ì…˜ "**{section_title}**"ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì€ ì´ˆì•ˆì„ ì‘ì„±í•´ë´¤ì–´ìš”:

```
{generated_content}
```

âš™ï¸ ê´œì°®ìœ¼ì‹ ê°€ìš”?
ë‚´ìš©ì„ ë°”ê¾¸ê³  ì‹¶ê±°ë‚˜, ë” ì¶”ê°€í•˜ê³  ì‹¶ì€ ë‚´ìš©ì´ ìˆë‹¤ë©´ ì•Œë ¤ì£¼ì„¸ìš”!
"""

# ì„¹ì…˜ ìœ„ì¹˜ì— ë”°ë¥¸ ë§ì¶¤í˜• í”„ë¡¬í”„íŠ¸
PROMPT_INTRO_SECTION = """
ì´ ê¸€ì˜ ì„œë¡  ë¶€ë¶„ì¸ "{section_title}"ì— ëŒ€í•œ ì´ˆì•ˆì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ ìš”ì†Œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
1. ì£¼ì œì— ëŒ€í•œ ê°„ê²°í•œ ì†Œê°œì™€ ì¤‘ìš”ì„±
2. ë…ìê°€ ì´ ê¸€ì„ ì½ì–´ì•¼ í•˜ëŠ” ì´ìœ 
3. ê¸€ì—ì„œ ë‹¤ë£° ë‚´ìš©ì— ëŒ€í•œ ê°„ëµí•œ ê°œìš”
4. ë…ìì˜ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆëŠ” í¥ë¯¸ë¡œìš´ ì‹œì‘ì 

ì£¼ì œ: {topic}
í‚¤ì›Œë“œ: {keywords}
ìŠ¤íƒ€ì¼: {style}
"""

PROMPT_BODY_SECTION = """
ì´ ê¸€ì˜ ë³¸ë¬¸ ë¶€ë¶„ì¸ "{section_title}"ì— ëŒ€í•œ ì´ˆì•ˆì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ ìš”ì†Œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
1. í•´ë‹¹ ì„¹ì…˜ì˜ í•µì‹¬ ê°œë… ì„¤ëª…
2. ì‹¤ì œ ì‘ë™í•˜ëŠ” ì½”ë“œ ì˜ˆì œì™€ ì„¤ëª…
3. ë‹¤ë¥¸ ì ‘ê·¼ë²•ê³¼ì˜ ë¹„êµ ë¶„ì„
4. ì‹¤ë¬´ ì ìš© ì‚¬ë¡€ ë˜ëŠ” ì˜ˆì‹œ

ì´ì „ ì„¹ì…˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ì„¸ìš”:
{previous_sections}

ì£¼ì œ: {topic}
í‚¤ì›Œë“œ: {keywords}
ìŠ¤íƒ€ì¼: {style}
"""

PROMPT_CONCLUSION_SECTION = """
ì´ ê¸€ì˜ ê²°ë¡  ë¶€ë¶„ì¸ "{section_title}"ì— ëŒ€í•œ ì´ˆì•ˆì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ ìš”ì†Œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
1. ê¸€ì—ì„œ ë‹¤ë£¬ í•µì‹¬ ë‚´ìš© ìš”ì•½
2. ì£¼ìš” ì‹œì‚¬ì  ë˜ëŠ” êµí›ˆ
3. ë…ìê°€ ë‹¤ìŒìœ¼ë¡œ íƒìƒ‰í•  ìˆ˜ ìˆëŠ” ê´€ë ¨ ì£¼ì œ ì œì•ˆ
4. ë…ìì˜ í–‰ë™ì„ ìœ ë„í•˜ëŠ” ë§ˆë¬´ë¦¬

ì´ì „ ì„¹ì…˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ì„¸ìš”:
{previous_sections}

ì£¼ì œ: {topic}
í‚¤ì›Œë“œ: {keywords}
ìŠ¤íƒ€ì¼: {style}
"""

# ìˆ˜ì • ìš”ì²­ì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸
PROMPT_REVISION = """
ë‹¤ìŒ ì„¹ì…˜ì˜ ì´ˆì•ˆì„ ìˆ˜ì •í•´ì£¼ì„¸ìš”:
ì„¹ì…˜ ì œëª©: {section_title}

ì‚¬ìš©ì ìš”ì²­: {user_request}

ê¸°ì¡´ ì´ˆì•ˆ:
{original_draft}

ì´ì „ ì„¹ì…˜ ë‚´ìš©:
{previous_sections}

ìˆ˜ì • ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ìœ ì˜í•˜ì„¸ìš”:
1. ì‚¬ìš©ìì˜ ìš”ì²­ì‚¬í•­ì„ ì •í™•íˆ ë°˜ì˜
2. ê¸°ìˆ ì  ì •í™•ì„± ìœ ì§€
3. ê¸€ì˜ ì „ì²´ì ì¸ ì¼ê´€ì„± ìœ ì§€
4. ì½”ë“œ ì˜ˆì œê°€ ìˆë‹¤ë©´ ì •í™•í•˜ê²Œ ìˆ˜ì •
5. ê¸°ì¡´ ì´ˆì•ˆì˜ ì¢‹ì€ ë¶€ë¶„ì€ ìœ ì§€

ì£¼ì œ: {topic}
í‚¤ì›Œë“œ: {keywords}
ìŠ¤íƒ€ì¼: {style}
"""

# Gemini ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
def get_chat_model():
    return genai.GenerativeModel("gemini-pro")

# ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.step = Step.TOPIC_QUESTION.value
    st.session_state.collected = {}
    st.session_state.generated_drafts = {}
    st.session_state.draft_index = 0

# ì‚¬ì´ë“œë°” ì§„í–‰ ë‹¨ê³„ í‘œì‹œ
with st.sidebar:
    st.markdown("### ğŸ§­ ì§„í–‰ ë‹¨ê³„")
    steps = [
        ("topic", "1. ì£¼ì œ ì…ë ¥"),
        ("keyword", "2. í‚¤ì›Œë“œ ì„ íƒ"),
        ("style", "3. ìŠ¤íƒ€ì¼ ì„¤ì •"),
        ("structure", "4. êµ¬ì¡° ì œì•ˆ"),
        ("subtitle", "5. ì†Œì œëª© êµ¬ì„±"),
        ("draft", "6. ì´ˆì•ˆ ì‘ì„±"),
        ("full_draft", "7. ì „ì²´ ì´ˆì•ˆ í™•ì¸")
    ]
    current_step = st.session_state.step
    for key, label in steps:
        if current_step.startswith(key):
            st.markdown(f"- **âœ… {label}**")
        else:
            st.markdown(f"- {label}")

# ì±— UI
st.title("ğŸ§  ê¸°ìˆ  ë¸”ë¡œê·¸ ì´ˆì•ˆ ìƒì„± ì±—ë´‡")
st.markdown("---")

# ë©”ì‹œì§€ ì¶œë ¥
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì±—ë´‡ ë©”ì‹œì§€ ì „ì†¡ í•¨ìˆ˜
def bot_say(message):
    st.session_state.messages.append({"role": "assistant", "content": message})
    with st.chat_message("assistant"):
        st.markdown(message)

# ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬ í•¨ìˆ˜
def user_say():
    user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)
        handle_input(user_input)

# AI ëª¨ë¸ì— ìš”ì²­í•˜ê³  ì‘ë‹µ ë°›ëŠ” ê³µí†µ í•¨ìˆ˜
def process_model_request(prompt):
    try:
        model = get_chat_model()
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        error_msg = f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        return error_msg

# ë‹¨ê³„ë³„ ì²˜ë¦¬ ë¡œì§
def handle_input(user_input):
    step = st.session_state.step

    # ì£¼ì œ ì§ˆë¬¸ ë‹¨ê³„
    if step == Step.TOPIC_QUESTION.value:
        st.session_state.step = Step.TOPIC_CONFIRM.value
        st.session_state.collected["user_topic"] = user_input

        prompt = f"""
{REACT_SYSTEM_PROMPT}

ì‚¬ìš©ì ì…ë ¥: "{user_input}"

ìœ„ ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ê¸°ìˆ  ë¸”ë¡œê·¸ ì£¼ì œë¥¼ ì¶”ë¡ í•´ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ê³ , ë‹¤ìŒ ì§ˆë¬¸ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥:

ì˜ˆì‹œ:
ğŸ§  ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì œê°€ ì´í•´í•œ ì£¼ì œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: "Postman ì‚¬ìš©ë²•"
âš™ï¸ ì´ ì£¼ì œë¡œ ë¸”ë¡œê·¸ë¥¼ ì‘ì„±í•˜ì‹œëŠ” ê²Œ ë§ì„ê¹Œìš”?
"""
        inferred_text = process_model_request(prompt)
        bot_say(inferred_text)

    # ì£¼ì œ í™•ì¸ ë‹¨ê³„
    elif step == Step.TOPIC_CONFIRM.value:
        if "ë„¤" in user_input:
            bot_say("ì¢‹ì•„ìš”! ì´ì œ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.")
            st.session_state.step = Step.KEYWORD_QUESTION.value
        else:
            bot_say("ì£¼ì œë¥¼ ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.")
            st.session_state.step = Step.TOPIC_QUESTION.value

    # í‚¤ì›Œë“œ ì§ˆë¬¸ ë‹¨ê³„
    elif step == Step.KEYWORD_QUESTION.value:
        st.session_state.collected["user_keywords_raw"] = user_input
        st.session_state.step = Step.KEYWORD_CONFIRM.value
        prompt = f"ì‚¬ìš©ìê°€ ì…ë ¥í•œ í‚¤ì›Œë“œ í›„ë³´: {user_input}\nìœ„ ë‚´ìš©ì„ ì •ë¦¬í•˜ì—¬ GPTê°€ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì œí•˜ê³ , í™•ì¸ ì§ˆë¬¸ í¬í•¨í•œ ë©”ì‹œì§€ ìƒì„±"
        response_text = process_model_request(prompt)
        bot_say(response_text)

    # í‚¤ì›Œë“œ í™•ì¸ ë‹¨ê³„
    elif step == Step.KEYWORD_CONFIRM.value:
        if "ë„¤" in user_input:
            bot_say("ìŠ¤íƒ€ì¼ì„ ì •í•´ë³¼ê²Œìš”. ë¬¸ì²´ì™€ ëŒ€ìƒ ë…ìë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.")
            st.session_state.step = Step.STYLE_QUESTION.value
        else:
            bot_say("ë‹¤ì‹œ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.session_state.step = Step.KEYWORD_QUESTION.value

    # ìŠ¤íƒ€ì¼ ì§ˆë¬¸ ë‹¨ê³„
    elif step == Step.STYLE_QUESTION.value:
        st.session_state.collected["user_style_raw"] = user_input
        st.session_state.step = Step.STYLE_CONFIRM.value
        prompt = f"ì‚¬ìš©ìê°€ ì…ë ¥í•œ ìŠ¤íƒ€ì¼: {user_input}\ní˜•ì‹, í†¤, ë…ìëŒ€ìƒì„ ì •ë¦¬í•˜ì—¬ í™•ì¸ ë©”ì‹œì§€ ìƒì„±"
        response_text = process_model_request(prompt)
        bot_say(response_text)

    # ìŠ¤íƒ€ì¼ í™•ì¸ ë‹¨ê³„
    elif step == Step.STYLE_CONFIRM.value:
        if "ë„¤" in user_input:
            bot_say("ì¢‹ì•„ìš”! ì´ì œ ê¸€ì˜ êµ¬ì¡°ë¥¼ ì œì•ˆë“œë¦´ê²Œìš”.")
            st.session_state.step = Step.STRUCTURE_SUGGEST.value
        else:
            bot_say("ìŠ¤íƒ€ì¼ì„ ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.session_state.step = Step.STYLE_QUESTION.value

    # êµ¬ì¡° ì œì•ˆ ë‹¨ê³„
    elif step == Step.STRUCTURE_SUGGEST.value:
        prompt = f"ì£¼ì œì™€ í‚¤ì›Œë“œ, ìŠ¤íƒ€ì¼ì„ ë°”íƒ•ìœ¼ë¡œ ë¸”ë¡œê·¸ì˜ ì „ì²´ êµ¬ì¡°ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”. ê° ì„¹ì…˜ì€ ì œëª©ë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”."
        response_text = process_model_request(prompt)
        st.session_state.collected["suggested_structure"] = response_text
        st.session_state.step = Step.STRUCTURE_CONFIRM.value
        bot_say(response_text + "\n\nì´ êµ¬ì¡°ë¡œ ê´œì°®ì„ê¹Œìš”?")

    # êµ¬ì¡° í™•ì¸ ë‹¨ê³„
    elif step == Step.STRUCTURE_CONFIRM.value:
        if "ë„¤" in user_input:
            bot_say("ì¢‹ìŠµë‹ˆë‹¤. ì´ì œ ê° ì†Œì œëª©ì„ í™•ì •í•˜ê² ìŠµë‹ˆë‹¤.")
            st.session_state.step = Step.SUBTITLE_CONFIRM.value
        else:
            bot_say("ì›í•˜ì‹œëŠ” êµ¬ì¡°ë¥¼ ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.")
            st.session_state.step = Step.STRUCTURE_SUGGEST.value

    # ì†Œì œëª© í™•ì¸ ë‹¨ê³„
    elif step == Step.SUBTITLE_CONFIRM.value:
        st.session_state.collected["finalized_subtitles"] = [s.strip() for s in user_input.split("\n") if s.strip()]
        st.session_state.step = Step.DRAFT_GENERATE.value
        st.session_state.draft_index = 0
        bot_say("ì´ì œ ê° ì„¹ì…˜ë³„ë¡œ ì´ˆì•ˆì„ ì‘ì„±í•´ë“œë¦´ê²Œìš”!")
        handle_input("")  # ìë™ìœ¼ë¡œ ì²« ì„¹ì…˜ ì´ˆì•ˆ ìƒì„± ì‹œì‘

    # ì´ˆì•ˆ ìƒì„± ë‹¨ê³„
    elif step == Step.DRAFT_GENERATE.value:
        subtitles = st.session_state.collected.get("finalized_subtitles", [])
        index = st.session_state.draft_index

        if index >= len(subtitles):
            st.session_state.step = Step.FULL_DRAFT.value
            handle_input("")  # ì „ì²´ ì´ˆì•ˆ í‘œì‹œ ìë™ í˜¸ì¶œ
            return

        current_section = subtitles[index]
        
        # ì´ì „ ì„¹ì…˜ ë‚´ìš© ìˆ˜ì§‘
        previous_sections = ""
        if index > 0:
            for i in range(index):
                prev_title = subtitles[i]
                prev_content = st.session_state.generated_drafts.get(prev_title, "")
                previous_sections += f"## {prev_title}\n{prev_content}\n\n"
        
        # ì„¹ì…˜ ìœ„ì¹˜ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ì„ íƒ
        section_prompt = ""
        if index == 0:
            # ì²« ë²ˆì§¸ ì„¹ì…˜ì€ ì„œë¡ ìœ¼ë¡œ ê°„ì£¼
            section_prompt = PROMPT_INTRO_SECTION.format(
                section_title=current_section,
                topic=st.session_state.collected.get('user_topic', ''),
                keywords=st.session_state.collected.get('user_keywords_raw', ''),
                style=st.session_state.collected.get('user_style_raw', '')
            )
        elif index == len(subtitles) - 1:
            # ë§ˆì§€ë§‰ ì„¹ì…˜ì€ ê²°ë¡ ìœ¼ë¡œ ê°„ì£¼
            section_prompt = PROMPT_CONCLUSION_SECTION.format(
                section_title=current_section,
                previous_sections=previous_sections,
                topic=st.session_state.collected.get('user_topic', ''),
                keywords=st.session_state.collected.get('user_keywords_raw', ''),
                style=st.session_state.collected.get('user_style_raw', '')
            )
        else:
            # ì¤‘ê°„ ì„¹ì…˜ì€ ë³¸ë¬¸ìœ¼ë¡œ ê°„ì£¼
            section_prompt = PROMPT_BODY_SECTION.format(
                section_title=current_section,
                previous_sections=previous_sections,
                topic=st.session_state.collected.get('user_topic', ''),
                keywords=st.session_state.collected.get('user_keywords_raw', ''),
                style=st.session_state.collected.get('user_style_raw', '')
            )
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ì„¹ì…˜ í”„ë¡¬í”„íŠ¸ ê²°í•©
        prompt = f"{REACT_SYSTEM_PROMPT}\n\n{section_prompt}"
        
        response_text = process_model_request(prompt)
        st.session_state.generated_drafts[current_section] = response_text
        st.session_state.step = Step.DRAFT_CONFIRM.value
        bot_say(f"âœï¸ ì„¹ì…˜ \"**{current_section}**\"ì˜ ì´ˆì•ˆì…ë‹ˆë‹¤:\n\n{response_text}\n\nì´ ë‚´ìš© ê´œì°®ìœ¼ì‹ ê°€ìš”? ìˆ˜ì •í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‘ì„±í•˜ê³  ì‹¶ìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”.")

    # ì´ˆì•ˆ í™•ì¸ ë‹¨ê³„
    elif step == Step.DRAFT_CONFIRM.value:
        if "ë„¤" in user_input:
            st.session_state.draft_index += 1
            st.session_state.step = Step.DRAFT_GENERATE.value
            handle_input("")  # ë‹¤ìŒ ì„¹ì…˜ ìë™ í˜¸ì¶œ
        else:
            current_section = list(st.session_state.generated_drafts.keys())[st.session_state.draft_index]
            original_draft = st.session_state.generated_drafts[current_section]
            
            # ì´ì „ ì„¹ì…˜ ë‚´ìš© ìˆ˜ì§‘
            subtitles = st.session_state.collected.get("finalized_subtitles", [])
            index = st.session_state.draft_index
            previous_sections = ""
            if index > 0:
                for i in range(index):
                    prev_title = subtitles[i]
                    prev_content = st.session_state.generated_drafts.get(prev_title, "")
                    previous_sections += f"## {prev_title}\n{prev_content}\n\n"
            
            # ìˆ˜ì • ìš”ì²­ í”„ë¡¬í”„íŠ¸ ìƒì„±
            revision_prompt = PROMPT_REVISION.format(
                section_title=current_section,
                user_request=user_input,
                original_draft=original_draft,
                previous_sections=previous_sections,
                topic=st.session_state.collected.get('user_topic', ''),
                keywords=st.session_state.collected.get('user_keywords_raw', ''),
                style=st.session_state.collected.get('user_style_raw', '')
            )
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ìˆ˜ì • í”„ë¡¬í”„íŠ¸ ê²°í•©
            prompt = f"{REACT_SYSTEM_PROMPT}\n\n{revision_prompt}"
            
            response_text = process_model_request(prompt)
            st.session_state.generated_drafts[current_section] = response_text
            bot_say(f"ğŸ” ë‹¤ì‹œ ì‘ì„±í•œ ì´ˆì•ˆì…ë‹ˆë‹¤:\n\n{response_text}\n\nì´ì œ ê´œì°®ìœ¼ì‹ ê°€ìš”?")

    # ì „ì²´ ì´ˆì•ˆ í‘œì‹œ ë‹¨ê³„
    elif step == Step.FULL_DRAFT.value:
        subtitles = st.session_state.collected.get("finalized_subtitles", [])
        full_draft = ""
        
        # ì œëª© ìƒì„±
        topic = st.session_state.collected.get('user_topic', '')
        full_draft += f"# {topic}\n\n"
        
        # ê° ì„¹ì…˜ ë‚´ìš© í•©ì¹˜ê¸°
        for subtitle in subtitles:
            content = st.session_state.generated_drafts.get(subtitle, "")
            full_draft += f"## {subtitle}\n{content}\n\n"
        
        # ì „ì²´ ì´ˆì•ˆ í‘œì‹œ
        st.session_state.step = Step.DONE.value
        bot_say(f"âœ… ëª¨ë“  ì´ˆì•ˆ ì‘ì„±ì„ ì™„ë£Œí–ˆì–´ìš”! ì•„ë˜ëŠ” ì „ì²´ ì´ˆì•ˆì…ë‹ˆë‹¤:\n\n{full_draft}\n\ní•„ìš”í•œ ê²½ìš° ìˆ˜ì •í•˜ê±°ë‚˜ ë³µì‚¬í•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”.")

# ì²« ì§ˆë¬¸ í‘œì‹œ
if not st.session_state.messages:
    bot_say(PROMPT_TOPIC_QUESTION)

# ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°
user_say()